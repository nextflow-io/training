= Modularization

The definition of module libraries simplifies the writing of complex data analysis pipelines and makes re-use of processes much easier.

Using the `hello.nf` example from earlier, we will convert the pipeline's processes into modules, then call them within the workflow scope in a variety of ways. 

== Modules

Nextflow DSL2 allows for the definition of stand-alone module scripts that can be included and shared across multiple workflows. Each module can contain its own `process` or `workflow` definition.

=== Importing modules

Components defined in the module script can be imported into other Nextflow scripts using the `include` statement. This allows you to store these components in a separate file(s) so that they can be re-used in multiple workflows.

Using the `hello.nf` example, we can achieve this by:

- Creating a file called `modules.nf` in the top-level directory.

- Cutting and pasting the two process definitions for `SPLITLETTERS` and `CONVERTTOUPPER` into `modules.nf`.

- Removing the `process` defintions in the `main.nf` script.

- Importing the processes from `modules.nf` within the `main.nf` script anywhere above the `workflow` definition:

[source,nextflow,linenums]
----
include { SPLITLETTERS   } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'
----

NOTE: In general, you would use relative paths to define the location of the module scripts using the `./` prefix.

[discrete]
=== Exercise

Create a `modules.nf` file with the previously defined processes from `hello.nf`. Then remove these processes from `hello.nf` and add the `include` definitions shown above.

.Click here for the answer:
[%collapsible]
====
The `hello.nf` script should look like this:
[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting  = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

include { SPLITLETTERS   } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'

workflow {
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.flatten())
    results_ch.view{ it }
}
----

You should have the following in the file `./modules.nf`:
[source,nextflow,linenums]
----
process SPLITLETTERS {
    
    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}

process CONVERTTOUPPER {
    
    input:
    file y

    output:
    stdout

    """
    cat $y | tr '[a-z]' '[A-Z]' 
    """
}
----
====

We now have modularized processes which makes the code more reusable and cleaner to read.

=== Multiple imports

If a Nextflow module script contains multiple `process` definitions they can also be imported using a single `include` statement as shown in the example below:

[source,nextflow,linenums]
----
include { SPLITLETTERS; CONVERTTOUPPER } from './modules.nf'
----

=== Module aliases

When including a module component it is possible to specify a name alias using the `as` declaration. 
This allows the inclusion and the invocation of the same component multiple times using different names. For example:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

include { SPLITLETTERS as SPLITLETTERS_one } from './modules.nf'
include { SPLITLETTERS as SPLITLETTERS_two } from './modules.nf'

include { CONVERTTOUPPER as CONVERTTOUPPER_one } from './modules.nf'
include { CONVERTTOUPPER as CONVERTTOUPPER_two } from './modules.nf'

workflow {
    letters_ch1 = SPLITLETTERS_one(greeting_ch)
    results_ch1 = CONVERTTOUPPER_one(letters_ch1.flatten())
    results_ch1.view{ it }

    letters_ch2 = SPLITLETTERS_two(greeting_ch)
    results_ch2 = CONVERTTOUPPER_two(letters_ch2.flatten())
    results_ch2.view{ it }
}
----

NOTE: You can store each process in separate files within separate sub-folders or combined in one big file (both are valid). For your own projects, it can be helpful to see examples on public repos. e.g. Seqera RNA-Seq tutorial 
https://github.com/seqeralabs/rnaseq-nf/tree/master/modules[here] or within nf-cores projects  https://github.com/nf-core/rnaseq/tree/master/modules/nf-core/modules[here].


== Output definition

In the previous example, we define the channel names to specify the input to the next process. 
We can also explicitly define the output of one process to another using the `.out` attribute. 
In this way, we can manipulate the output of a process, as shown below:

[source,nextflow,linenums]
----
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.out.flatten())
----

This can then be used to define specific outputs. FOr example, if a process defines two or more output channels, each channel can be accessed by indexing the `.out` attribute, e.g., `.out[0]`, `.out[1]`, etc.

Additionally, the process `output` definition allows the use of the `emit` statement to define a named identifier that can be used to reference the channel in the external scope. 

For example, check the `emit` statement on the `CONVERTTOUPPER` process in the following `./modules.nf` snippet:

[source,nextflow,linenums]
----
process SPLITLETTERS {
    input:
    val x

    output:
    file 'chunk_*'

    """
    printf '$x' | split -b 6 - chunk_
    """
}

process CONVERTTOUPPER {
    input:
    file y

    output:
    stdout emit: upper

    """
    cat $y | tr '[a-z]' '[A-Z]'
    """
}
----

And how it is used in the `hello.nf` script:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'
greeting_ch = Channel.from(params.greeting)

include { SPLITLETTERS   } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'

workflow {
    letters_ch = SPLITLETTERS(greeting_ch)
    results_ch = CONVERTTOUPPER(letters_ch.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}
----

=== Using piped outputs

Another way to deal with outputs in the workflow scope is to use pipes `|`. 

[discrete]
=== Exercise

Try changing the workflow script to the snippet below:

[source,nextflow,linenums]
----
workflow {
    Channel.from(params.greeting) | SPLITLETTERS | flatten() | CONVERTTOUPPER | view
}
----

Here we use a https://www.nextflow.io/docs/latest/dsl2.html#pipes[pipe] which passed the output as a channel to the next process.


=== Workflow definition

The `workflow` scope allows the definition of components that define the invocation of one or more processes or operators:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'

include { SPLITLETTERS } from './modules.nf'
include { CONVERTTOUPPER } from './modules.nf'


workflow my_pipeline {
    SPLITLETTERS(params.greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}

workflow {
    my_pipeline()
}
----

For example, the snippet above defines a `workflow` named `my_pipeline`, that can be invoked via another `workflow` definition.

=== Workflow parameters

A workflow component can access any variable or parameter defined in the outer scope. In the running example, we can also access `params.greeting` directly within the `workflow` definition.

[source,nextflow,linenums]
----
params.greeting = 'Hello world!'

workflow my_pipeline {
    SPLITLETTERS(Channel.from(params.greeting))
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}

workflow {
    my_pipeline()
}
----

=== Workflow inputs

A `workflow` component can declare one or more input channels using the `take` statement. For example:

[source,nextflow,linenums]
----
params.greeting = 'Hello world!'

workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())
    CONVERTTOUPPER.out.upper.view{ it }
}
----

IMPORTANT: When the `take` statement is used, the `workflow` definition needs to be declared within the `main` block.

The input for the `workflow` can then be specified as an argument:

[source,nextflow,linenums]
----
workflow {
    my_pipeline(Channel.from(params.greeting))
}
----

=== Workflow outputs

A `workflow` can declare one or more output channels using the `emit` statement. For example:

[source,nextflow,linenums]
----
workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())

    emit:
    CONVERTTOUPPER.out.upper
}

workflow {
    my_pipeline(Channel.from(params.greeting))
    my_pipeline.out.view()
}
----

As a result, we can use the `my_pipeline.out` notation to access the outputs of `my_pipeline` in the invoking `workflow`.

We can also declare named outputs within the `emit` block.

[source,nextflow,linenums]
----
workflow my_pipeline {
    take:
    greeting

    main:
    SPLITLETTERS(greeting)
    CONVERTTOUPPER(SPLITLETTERS.out.flatten())

    emit:
    my_data = CONVERTTOUPPER.out.upper
}

workflow {
    my_pipeline(Channel.from(params.greeting))
    my_pipeline.out.my_data.view()
}
----

The result of the above snippet can then be accessed using `my_pipeline.out.my_data`.


=== Named workflow calling

In a `main.nf` script we can have multiple workflows. In which case we may want to call a specific workflow when running the code.
For this we use the entrypoint call `-entry <workflow_name>`.


[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.greeting = 'Hello world!'

include { SPLITLETTERS as SPLITLETTERS_one } from './modules.nf'
include { SPLITLETTERS as SPLITLETTERS_two } from './modules.nf'

include { CONVERTTOUPPER as CONVERTTOUPPER_one } from './modules.nf'
include { CONVERTTOUPPER as CONVERTTOUPPER_two } from './modules.nf'


workflow my_pipeline_one {
    letters_ch1 = SPLITLETTERS_one(params.greeting)
    results_ch1 = CONVERTTOUPPER_one(letters_ch1.flatten())
    results_ch1.view{ it }
}

workflow my_pipeline_two {
    letters_ch2 = SPLITLETTERS_two(params.greeting)
    results_ch2 = CONVERTTOUPPER_two(letters_ch2.flatten())
    results_ch2.view{ it }
}

workflow {
    my_pipeline_one(Channel.from(params.greeting))
    my_pipeline_one.out.my_data.view()

    my_pipeline_two(Channel.from(params.greeting))
    my_pipeline_two.out.my_data.view()
}
----


=== Parameter scopes

A module script can define one or more parameters or custom functions using the same syntax as with any other Nextflow script. Using the minimal examples below: 

[discrete]
==== Module script (`./modules.nf`)

[source,nextflow,linenums]
----
params.foo = 'Hello'
params.bar = 'world!'

def SAYHELLO() {
    println "$params.foo $params.bar"
}
----

[discrete]
==== Main script (`./main.nf`)

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.foo = 'Hola'
params.bar = 'mundo!'

include { SAYHELLO } from './modules.hello.nf'

workflow {
    SAYHELLO()
}
----

Running `main.nf` should print:

[source,bash,linenums]
----
Hola mundo!
----

As highlighted above, the script will print `Hola mundo!` instead of `Hello world!` because parameters are inherited from the including context.

TIP: To avoid being ignored, pipeline parameters should be defined at the beginning of the script before any `include` declarations.

The `addParams` option can be used to extend the module parameters without affecting the external scope. For example:

[source,nextflow,linenums]
----
#!/usr/bin/env nextflow

params.foo = 'Hola'
params.bar = 'mundo!'

include { SAYHELLO } from './modules.nf' addParams(foo: 'Ciao')

workflow {
    SAYHELLO()
}
----

Executing the main script above should print:

[source,bash,linenums]
----
Ciao mundo!
----


== DSL2 migration notes

To view a summary of the changes introduced when Nextflow migrated from DSL1 to DSL2 please refer to the https://www.nextflow.io/docs/latest/dsl2.html#dsl2-migration-notes[DSL2 migration notes] in the official Nextflow documentation.
